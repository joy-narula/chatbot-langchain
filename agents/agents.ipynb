{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results = 1, doc_content_chars_max=200)\n",
    "wiki_tool = WikipediaAPIWrapper(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/\")\n",
    "docs = loader.load()\n",
    "\n",
    "documents = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200).split_documents(docs)\n",
    "\n",
    "vectordb = FAISS.from_documents(documents, OpenAIEmbeddings())\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retrieve_tool = create_retriever_tool(retriever, \"langsmith_search\", \"Search for information about langsmith. For any questions about Langsmith, you should use this tool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results = 1, doc_content_chars_max = 200)\n",
    "arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, retrieve_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Agents use language models to choose sequence of actions, while in chains sequence is pre defined, agents use language models for reasoning. Here agent will use the tools to search for information from different sources \n",
    "\"\"\"\n",
    "# Agents\n",
    "from langchain.agents import create_openai_tools_agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentExecutor(verbose=True, agent=RunnableMultiActionAgent(runnable=RunnableAssign(mapper={\n",
       "  agent_scratchpad: RunnableLambda(lambda x: format_to_openai_tool_messages(x['intermediate_steps']))\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], optional_variables=['chat_history'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x117e179a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]], 'agent_scratchpad': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x117e179a0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={'chat_history': []}, metadata={'lc_hub_owner': 'hwchase17', 'lc_hub_repo': 'openai-functions-agent', 'lc_hub_commit_hash': 'a1655024b06afbd95d17449f21316291e0726f13dcfaf990cc0d18087ad689a5'}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), MessagesPlaceholder(variable_name='agent_scratchpad')])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x130a5d750>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x130a5f850>, root_client=<openai.OpenAI object at 0x130756bf0>, root_async_client=<openai.AsyncOpenAI object at 0x130a5d7b0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'arxiv', 'description': 'A wrapper around Arxiv.org Useful for when you need to answer questions about Physics, Mathematics, Computer Science, Quantitative Biology, Quantitative Finance, Statistics, Electrical Engineering, and Economics from scientific articles on arxiv.org. Input should be a search query.', 'parameters': {'properties': {'query': {'description': 'search query to look up', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'langsmith_search', 'description': 'Search for information about langsmith. For any questions about Langsmith, you should use this tool', 'parameters': {'properties': {'query': {'description': 'query to look up in retriever', 'type': 'string'}}, 'required': ['query'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| OpenAIToolsAgentOutputParser(), input_keys_arg=[], return_keys_arg=[], stream_runnable=True), tools=[ArxivQueryRun(api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=1, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=200)), Tool(name='langsmith_search', description='Search for information about langsmith. For any questions about Langsmith, you should use this tool', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x118986170>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x130800bb0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'), coroutine=functools.partial(<function _aget_relevant_documents at 0x118cc31c0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x130800bb0>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n'))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agent Executor\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'Langsmith'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ğŸ¦œï¸�ğŸ› ï¸� LangSmith\n",
      "\n",
      "Skip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceQuick StartOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain's open source frameworks is not necessary - LangSmith works on its own!\n",
      "1. Install LangSmithâ€‹\n",
      "PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n",
      "2. Create an API keyâ€‹\n",
      "To create an API key head to the Settings page. Then click Create API Key.\n",
      "3. Set up your environmentâ€‹\n",
      "Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>\n",
      "4. Log your first traceâ€‹\n",
      "\n",
      "Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n",
      "and explore the results of your evaluation.\n",
      "Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\n",
      "\n",
      "4. Log your first traceâ€‹\n",
      "LangSmith + LangChain OSSYou don't need to use the LangSmith SDK directly if your application is built on LangChain/LangGraph (either Python and JS).See the how-to guide for tracing with LangChain here.\n",
      "We provide multiple ways to log traces to LangSmith. Below, we'll highlight\n",
      "how to use traceable(). See more on the Annotate code for tracing page.\u001b[0m\u001b[32;1m\u001b[1;3mLangsmith is a platform designed for building production-grade applications using large language models (LLMs). It emphasizes the ability to closely monitor and evaluate applications, enabling developers to deploy their solutions quickly and confidently. Here are some key features and steps to get started with Langsmith:\n",
      "\n",
      "1. **Installation**: You can install Langsmith using Python or TypeScript. For Python, you can use the command:\n",
      "   ```bash\n",
      "   pip install -U langsmith openai\n",
      "   ```\n",
      "   For TypeScript, you can use:\n",
      "   ```bash\n",
      "   yarn add langsmith openai\n",
      "   ```\n",
      "\n",
      "2. **API Key Creation**: To use Langsmith, you need to create an API key. This can be done from the Settings page of the platform.\n",
      "\n",
      "3. **Environment Setup**: You need to set up your environment variables, including the LangChain tracing and API keys.\n",
      "\n",
      "4. **Logging Traces**: After setting up, you can log your first trace and access the LangSmith experiments UI to explore the results of your evaluations.\n",
      "\n",
      "Langsmith operates independently and does not require the use of LangChain's open-source frameworks, although it can integrate with them if desired. The platform provides various resources, including tutorials and guides, to help users effectively evaluate their applications.\n",
      "\n",
      "For more detailed information, you can refer to the official Langsmith documentation and community resources.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Langsmith',\n",
       " 'output': \"Langsmith is a platform designed for building production-grade applications using large language models (LLMs). It emphasizes the ability to closely monitor and evaluate applications, enabling developers to deploy their solutions quickly and confidently. Here are some key features and steps to get started with Langsmith:\\n\\n1. **Installation**: You can install Langsmith using Python or TypeScript. For Python, you can use the command:\\n   ```bash\\n   pip install -U langsmith openai\\n   ```\\n   For TypeScript, you can use:\\n   ```bash\\n   yarn add langsmith openai\\n   ```\\n\\n2. **API Key Creation**: To use Langsmith, you need to create an API key. This can be done from the Settings page of the platform.\\n\\n3. **Environment Setup**: You need to set up your environment variables, including the LangChain tracing and API keys.\\n\\n4. **Logging Traces**: After setting up, you can log your first trace and access the LangSmith experiments UI to explore the results of your evaluations.\\n\\nLangsmith operates independently and does not require the use of LangChain's open-source frameworks, although it can integrate with them if desired. The platform provides various resources, including tutorials and guides, to help users effectively evaluate their applications.\\n\\nFor more detailed information, you can refer to the official Langsmith documentation and community resources.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'state of the art LLM models'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2024-05-30\n",
      "Title: A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models\n",
      "Authors: Eduard Frankford, Ingo Höhn, Clemens Sauerwein, Ruth Breu\n",
      "Su\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'large language models'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2023-06-12\n",
      "Title: Lost in Translation: Large Language Models in Non-English Content Analysis\n",
      "Authors: Gabriel Nicholas, Aliya Bhatia\n",
      "Summary: In recent years, large language models (e.g., O\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `arxiv` with `{'query': 'latest advancements in large language models'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPublished: 2024-04-13\n",
      "Title: Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies\n",
      "Authors: Benjue Weng\n",
      "Summary: With the surge\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `langsmith_search` with `{'query': 'state of the art LLM models'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mGet started with LangSmith | ğŸ¦œï¸�ğŸ› ï¸� LangSmith\n",
      "\n",
      "Skip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Cloud)AdministrationSelf-hostingReferenceQuick StartOn this pageGet started with LangSmith\n",
      "LangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence. Use of LangChain's open source frameworks is not necessary - LangSmith works on its own!\n",
      "1. Install LangSmithâ€‹\n",
      "PythonTypeScriptpip install -U langsmith openaiyarn add langsmith openai\n",
      "2. Create an API keyâ€‹\n",
      "To create an API key head to the Settings page. Then click Create API Key.\n",
      "3. Set up your environmentâ€‹\n",
      "Shellexport LANGCHAIN_TRACING_V2=trueexport LANGCHAIN_API_KEY=<your-api-key># The below examples use the OpenAI API, though it's not necessary in generalexport OPENAI_API_KEY=<your-openai-api-key>\n",
      "4. Log your first traceâ€‹\n",
      "\n",
      "Click the link printed out by your evaluation run to access the LangSmith experiments UI,\n",
      "and explore the results of your evaluation.\n",
      "Learn more about evaluation in the tutorials, conceptual guide, and how-to guides.\n",
      "Was this page helpful?You can leave detailed feedback on GitHub.NextConcepts1. Install LangSmith2. Create an API key3. Set up your environment4. Log your first trace5. Run your first evaluationCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright Â© 2024 LangChain, Inc.\n",
      "\n",
      "5. Run your first evaluationâ€‹\n",
      "Evaluation requires a system to test, data to serve as test cases, and optionally evaluators to grade the results. Here we use a built-in accuracy evaluator.\u001b[0m\u001b[32;1m\u001b[1;3mHere are some recent insights and publications regarding the state-of-the-art in large language models (LLMs):\n",
      "\n",
      "1. **Survey on Programming Exercise Generation**:\n",
      "   - **Title**: A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models\n",
      "   - **Authors**: Eduard Frankford, Ingo Höhn, Clemens Sauerwein, Ruth Breu\n",
      "   - **Published**: May 30, 2024\n",
      "   - This paper surveys the advancements in using LLMs for generating programming exercises, highlighting the capabilities and methodologies employed in this domain.\n",
      "\n",
      "2. **Non-English Content Analysis**:\n",
      "   - **Title**: Lost in Translation: Large Language Models in Non-English Content Analysis\n",
      "   - **Authors**: Gabriel Nicholas, Aliya Bhatia\n",
      "   - **Published**: June 12, 2023\n",
      "   - This work discusses the application of LLMs in analyzing non-English content, addressing challenges and opportunities in multilingual contexts.\n",
      "\n",
      "3. **Comprehensive Review of LLMs**:\n",
      "   - **Title**: Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies\n",
      "   - **Author**: Benjue Weng\n",
      "   - **Published**: April 13, 2024\n",
      "   - This review provides an extensive analysis of various paradigms and fine-tuning strategies for LLMs, summarizing the current landscape and future directions.\n",
      "\n",
      "### LangSmith Overview\n",
      "LangSmith is a platform designed for building production-grade LLM applications. It offers tools for monitoring and evaluating LLM applications, allowing developers to deploy confidently. Key features include:\n",
      "- Easy installation and setup.\n",
      "- API integration for logging and evaluation.\n",
      "- Support for both Python and TypeScript environments.\n",
      "\n",
      "For more detailed information, you can explore the LangSmith documentation and resources.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'state of the art llm models',\n",
       " 'output': 'Here are some recent insights and publications regarding the state-of-the-art in large language models (LLMs):\\n\\n1. **Survey on Programming Exercise Generation**:\\n   - **Title**: A Survey Study on the State of the Art of Programming Exercise Generation using Large Language Models\\n   - **Authors**: Eduard Frankford, Ingo Höhn, Clemens Sauerwein, Ruth Breu\\n   - **Published**: May 30, 2024\\n   - This paper surveys the advancements in using LLMs for generating programming exercises, highlighting the capabilities and methodologies employed in this domain.\\n\\n2. **Non-English Content Analysis**:\\n   - **Title**: Lost in Translation: Large Language Models in Non-English Content Analysis\\n   - **Authors**: Gabriel Nicholas, Aliya Bhatia\\n   - **Published**: June 12, 2023\\n   - This work discusses the application of LLMs in analyzing non-English content, addressing challenges and opportunities in multilingual contexts.\\n\\n3. **Comprehensive Review of LLMs**:\\n   - **Title**: Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies\\n   - **Author**: Benjue Weng\\n   - **Published**: April 13, 2024\\n   - This review provides an extensive analysis of various paradigms and fine-tuning strategies for LLMs, summarizing the current landscape and future directions.\\n\\n### LangSmith Overview\\nLangSmith is a platform designed for building production-grade LLM applications. It offers tools for monitoring and evaluating LLM applications, allowing developers to deploy confidently. Key features include:\\n- Easy installation and setup.\\n- API integration for logging and evaluation.\\n- Support for both Python and TypeScript environments.\\n\\nFor more detailed information, you can explore the LangSmith documentation and resources.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"state of the art llm models\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
